{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55dca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vnstock import *\n",
    "from datetime import *\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e7b4f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IncomeStatement and Balancesheet\n",
    "\n",
    "#df = financial_report(symbol='DSN', report_type='IncomeStatement', frequency='Quarterly', periods=100, latest_year=None)\n",
    "#df2 = financial_report(symbol='DSN', report_type='BalanceSheet', frequency='quarterly', periods=100, latest_year=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50a6924",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/atlas/OneDrive/Desktop/vnstock/ratio.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/atlas/OneDrive/Desktop/vnstock/ratio.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file_path)\n\u001b[0;32m      4\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/atlas/OneDrive/Desktop/vnstock/price.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m price_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/atlas/OneDrive/Desktop/vnstock/ratio.csv'"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'C:/Users/atlas/OneDrive/Desktop/vnstock/ratio.csv'\n",
    "result_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "csv_file_path = 'C:/Users/atlas/OneDrive/Desktop/vnstock/price.csv'\n",
    "price_df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "532fd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called price_df\n",
    "\n",
    "# Convert the 'time' column to datetime\n",
    "price_df['time'] = pd.to_datetime(price_df['time'])\n",
    "\n",
    "# Sort the DataFrame by 'time' column\n",
    "price_df.sort_values(by='time', inplace=True)\n",
    "\n",
    "# Calculate the latest price for each ticker\n",
    "latest_prices = price_df.groupby('ticker')['close'].last()\n",
    "\n",
    "# Map the latest prices to the DataFrame based on ticker\n",
    "price_df['latest_price'] = price_df['ticker'].map(latest_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0d609866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_reporting_time(range_column):\n",
    "    # Extract year and quarter from the 'range' column\n",
    "    year = range_column.str.split('-').str[1].astype(int)\n",
    "    quarter = range_column.str.split('-').str[0]\n",
    "    \n",
    "    # Define a mapping from quarter to month\n",
    "    quarter_to_month = {'Q1': '03', 'Q2': '06', 'Q3': '09', 'Q4': '12'}\n",
    "    \n",
    "    # Create the 'reporting_time' column by combining year and month\n",
    "    reporting_time = year.astype(str) + '-' + quarter.map(quarter_to_month)\n",
    "    \n",
    "    return reporting_time\n",
    "\n",
    "def create_buying_time(reporting_time_column):\n",
    "    # Convert 'reporting_time' column to datetime format\n",
    "    reporting_time = pd.to_datetime(reporting_time_column)\n",
    "    \n",
    "    # Add 1 month to the 'reporting_time' column\n",
    "    buying_time = reporting_time + pd.DateOffset(months=1)\n",
    "    \n",
    "    # Round datetime values to the beginning of the month\n",
    "    buying_time = buying_time - pd.to_timedelta(buying_time.dt.day - 1, unit='d')\n",
    "    \n",
    "    # Extract only year and month from the datetime and format it as 'YYYY-MM'\n",
    "    buying_time = buying_time.dt.strftime('%Y-%m')\n",
    "    \n",
    "    return buying_time\n",
    "\n",
    "def create_selling_time(buying_time_column):\n",
    "    # Convert 'buying_time' column to datetime format\n",
    "    buying_time = pd.to_datetime(buying_time_column)\n",
    "    \n",
    "    # Add 1 year to the 'buying_time' column\n",
    "    selling_time = buying_time + pd.DateOffset(years=1)\n",
    "    \n",
    "    # Convert 'selling_time' column to year-month format\n",
    "    selling_time = selling_time.dt.strftime('%Y-%m')\n",
    "    \n",
    "    return selling_time\n",
    "\n",
    "# Example usage assuming you have a DataFrame called result_df with a column 'range'\n",
    "# Create 'reporting_time' column\n",
    "result_df['reporting_time'] = create_reporting_time(result_df['range'])\n",
    "\n",
    "# Create 'buying_time' column\n",
    "result_df['buying_time'] = create_buying_time(result_df['reporting_time'])\n",
    "\n",
    "# Create 'selling_time' column\n",
    "result_df['selling_time'] = create_selling_time(result_df['buying_time'])\n",
    "\n",
    "# Convert 'buying_time' to datetime format and then to 'YYYY-MM' format\n",
    "result_df['buying_time'] = pd.to_datetime(result_df['buying_time'])\n",
    "result_df['buying_time'] = result_df['buying_time'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Subtract 1 year from 'buying_time' to get 'last_year_time'\n",
    "result_df['last_year_time'] = pd.to_datetime(result_df['buying_time']) - pd.DateOffset(years=1)\n",
    "result_df['last_year_time'] = result_df['last_year_time'].dt.strftime('%Y-%m')\n",
    "result_df['buying_year'] = result_df['buying_time'].apply(lambda x: int(x.split('-')[0]))\n",
    "result_df['reporting_year'] = result_df['reporting_time'].apply(lambda x: int(x.split('-')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9eb8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['ROA flag'] = [0 if val <= 0.25 else 1 for val in result_df['roa']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a262690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [time, open, high, low, close, volume, ticker, yearmonth, max_price_ever, Avg12M, Min12M, Max12M, year, max_prev_years, latest_price]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "price_df['time'] = pd.to_datetime(price_df['time'])\n",
    "\n",
    "price_df['yearmonth'] = price_df['time'].dt.strftime('%Y-%m')\n",
    "\n",
    "\n",
    "# Check for duplicates based on 'ticket' and 'yearmonth' columns\n",
    "duplicate_rows = price_df.duplicated(subset=['ticker', 'yearmonth'], keep=False)\n",
    "\n",
    "# Display duplicate rows (if any)\n",
    "print(price_df[duplicate_rows])\n",
    "\n",
    "# Drop duplicate rows based on 'ticket' and 'yearmonth' columns\n",
    "price_df.drop_duplicates(subset=['ticker', 'yearmonth'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f1adcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buying price\n",
    "merged_df = pd.merge(result_df, price_df[['ticker', 'yearmonth', 'close']], \n",
    "                     left_on=['ticker', 'buying_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'close': 'buying_price'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# selling price\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'close']], \n",
    "                     left_on=['ticker', 'selling_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'close': 'selling_price'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reporting price\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'close']], \n",
    "                     left_on=['ticker', 'reporting_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'close': 'reporting_price'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "\n",
    "# last year price\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'close']], \n",
    "                     left_on=['ticker', 'last_year_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'close': 'last_year_price'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# max ever price\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'max_price_ever']], \n",
    "                     left_on=['ticker', 'buying_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'max_price_ever': 'max_price_ever'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "\n",
    "# max prev years\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'max_prev_years']], \n",
    "                     left_on=['ticker', 'buying_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'max_prev_years': 'max_prev_years'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "# Avg12M\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'Avg12M']], \n",
    "                     left_on=['ticker', 'buying_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'Avg12M': 'Avg12M'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "# Min12M\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'Min12M']], \n",
    "                     left_on=['ticker', 'buying_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'Min12M': 'Min12M'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)\n",
    "\n",
    "\n",
    "# latest price\n",
    "merged_df = pd.merge(merged_df, price_df[['ticker', 'yearmonth', 'latest_price']], \n",
    "                     left_on=['ticker', 'buying_time'], right_on=['ticker', 'yearmonth'], \n",
    "                     how='left')\n",
    "merged_df.rename(columns={'latest_price': 'latest_price'}, inplace=True)\n",
    "merged_df.drop(columns=['yearmonth'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7ed50c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['reporting_price'] = merged_df['reporting_price'].astype(float)\n",
    "merged_df['earningPerShare'] = merged_df['earningPerShare'].astype(float)\n",
    "merged_df['PE'] = merged_df['reporting_price'] / merged_df['earningPerShare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2ab4bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['PE2'] = merged_df['priceToEarning'].fillna(merged_df['PE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d6f4e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas from 'selling_price' and 'buying_price' columns\n",
    "#merged_df['selling_price'] = merged_df['selling_price'].str.replace(',', '')\n",
    "#merged_df['buying_price'] = merged_df['buying_price'].str.replace(',', '')\n",
    "\n",
    "# Remove commas from 'selling_price' and 'buying_price' columns\n",
    "merged_df['selling_price'] = merged_df['selling_price'].replace(',', '', regex=True)\n",
    "merged_df['buying_price'] = merged_df['buying_price'].replace(',', '', regex=True)\n",
    "\n",
    "\n",
    "# Convert 'selling_price' and 'buying_price' columns to float\n",
    "merged_df['selling_price'] = merged_df['selling_price'].astype(float)\n",
    "merged_df['buying_price'] = merged_df['buying_price'].astype(float)\n",
    "\n",
    "# Remove commas from 'selling_price' and 'buying_price' columns\n",
    "#merged_df['last_year_price'] = merged_df['last_year_price'].str.replace(',', '')\n",
    "merged_df['last_year_price'] = merged_df['last_year_price'].replace(',', '', regex=True)\n",
    "\n",
    "# Convert 'selling_price' and 'buying_price' columns to float\n",
    "merged_df['last_year_price'] = merged_df['last_year_price'].astype(float)\n",
    "\n",
    "# Remove commas from 'selling_price' and 'buying_price' columns\n",
    "#merged_df['last_year_price'] = merged_df['last_year_price'].str.replace(',', '')\n",
    "merged_df['max_prev_years'] = merged_df['max_prev_years'].replace(',', '', regex=True)\n",
    "\n",
    "# Convert 'selling_price' and 'buying_price' columns to float\n",
    "merged_df['max_prev_years'] = merged_df['max_prev_years'].astype(float)\n",
    "\n",
    "# Remove commas from 'selling_price' and 'buying_price' columns\n",
    "merged_df['max_price_ever'] = merged_df['max_price_ever'].str.replace(',', '')\n",
    "\n",
    "# Convert 'selling_price' and 'buying_price' columns to float\n",
    "merged_df['max_price_ever'] = merged_df['max_price_ever'].astype(float)\n",
    "\n",
    "\n",
    "# Remove commas from 'selling_price' and 'buying_price' columns\n",
    "merged_df['Avg12M'] = merged_df['Avg12M'].str.replace(',', '')\n",
    "\n",
    "# Convert 'selling_price' and 'buying_price' columns to float\n",
    "merged_df['Avg12M'] = merged_df['Avg12M'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9280b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df['return'] = merged_df['selling_price'] / merged_df['buying_price'] - 1\n",
    "\n",
    "# If selling_price is not available (null), use latest_price for calculation\n",
    "merged_df['return'] = merged_df.apply(lambda row: (row['latest_price'] / row['buying_price'] - 1) if pd.isnull(row['selling_price']) else (row['selling_price'] / row['buying_price'] - 1), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c83f7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[(merged_df['PE2'] != 'tex') & (merged_df['PE2'].notnull()) & (merged_df['PE2'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "58251b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming merged_df is your DataFrame\n",
    "\n",
    "# Calculate ranking for priceToEarning\n",
    "merged_df['ranking_pe'] = merged_df.groupby('range')['PE2'].rank(ascending=True, method='dense')\n",
    "\n",
    "# Fill NaN or infinite values with -1\n",
    "merged_df['ranking_pe'].fillna(-1, inplace=True)\n",
    "merged_df['ranking_pe'] = merged_df['ranking_pe'].astype(int)\n",
    "\n",
    "# Calculate ranking for roa\n",
    "merged_df['ranking_roa'] = merged_df.groupby('range')['roa'].rank(ascending=False, method='dense')\n",
    "\n",
    "# Fill NaN or infinite values with -1\n",
    "merged_df['ranking_roa'].fillna(-1, inplace=True)\n",
    "merged_df['ranking_roa'] = merged_df['ranking_roa'].astype(int)\n",
    "\n",
    "# Create a new column called total_ranking\n",
    "merged_df['total_ranking'] = merged_df['ranking_pe'] + merged_df['ranking_roa']\n",
    "\n",
    "# Create a new column called final_ranking based on total_ranking\n",
    "merged_df['final_ranking'] = merged_df.groupby('range')['total_ranking'].rank(ascending=True, method='dense').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "88145440",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Top selection flag'] = [1 if val <= 7 else 0 for val in merged_df['final_ranking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f76e6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price increase for last month\n",
    "merged_df['price_increase_last_month'] = merged_df['buying_price'] / merged_df['reporting_price'] - 1\n",
    "\n",
    "# Calculate price increase for last year\n",
    "merged_df['price_increase_last_year'] = merged_df['buying_price'] / merged_df['last_year_price'] - 1\n",
    "\n",
    "\n",
    "merged_df['price_flag (increase from last month)'] = np.where(\n",
    "    (merged_df['price_increase_last_month'] > 0) & \n",
    "    (merged_df['price_increase_last_month'] < 0.3), 1, 0\n",
    ")\n",
    "\n",
    "merged_df['price_flag (increase from last year)'] = np.where(\n",
    "    (merged_df['price_increase_last_month'] > 0), 1, 0\n",
    ")\n",
    "\n",
    "# Create 'price_flag (increase from max ever)' column\n",
    "merged_df['price_flag (increase from max ever)'] = np.where(\n",
    "    (merged_df['buying_price'] > merged_df['max_price_ever']), 1, 0\n",
    ")\n",
    "\n",
    "\n",
    "# Create 'price_flag (increase from max ever)' column\n",
    "merged_df['price_flag (increase from prev years)'] = np.where(\n",
    "    (merged_df['buying_price'] > merged_df['max_prev_years']), 1, 0\n",
    ")\n",
    "\n",
    "# Ensure that 'Min12M' doesn't have any non-numeric values after conversion\n",
    "merged_df['price_increase_from_Min12M'] = merged_df['buying_price'] / merged_df['Min12M'].replace([np.inf, -np.inf], np.nan).fillna(0) - 1\n",
    "\n",
    "\n",
    "merged_df['price_flag (increase from Min12M)'] = np.where(\n",
    "    (merged_df['price_increase_from_Min12M'] > 2), 0, 1\n",
    ")\n",
    "\n",
    "\n",
    "merged_df['price_flag (increase from Avg12M)'] = np.where(\n",
    "    (merged_df['buying_price'] > merged_df['Avg12M']), 1, 0\n",
    ")\n",
    "\n",
    "\n",
    "merged_df['buying_month'] = merged_df['buying_time'].str.split('-').str[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7c9722a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['G7'] = merged_df['ROA flag'] +  merged_df['Top selection flag'] + merged_df['price_flag (increase from last month)'] + merged_df['price_flag (increase from last year)'] + merged_df['price_flag (increase from prev years)'] + merged_df['price_flag (increase from Min12M)'] + merged_df['price_flag (increase from Avg12M)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1dbc1dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_year</th>\n",
       "      <th>ticker</th>\n",
       "      <th>buying_time</th>\n",
       "      <th>selling_time</th>\n",
       "      <th>return</th>\n",
       "      <th>buying_price</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>latest_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>VIP</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>2024-07</td>\n",
       "      <td>-7.8%</td>\n",
       "      <td>12,200</td>\n",
       "      <td>nan</td>\n",
       "      <td>11,250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>DSN</td>\n",
       "      <td>2023-04</td>\n",
       "      <td>2024-04</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>53,920</td>\n",
       "      <td>nan</td>\n",
       "      <td>56,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>ST8</td>\n",
       "      <td>2022-07</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>52.2%</td>\n",
       "      <td>15,700</td>\n",
       "      <td>23,900</td>\n",
       "      <td>10,550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>ADP</td>\n",
       "      <td>2021-04</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>22.2%</td>\n",
       "      <td>17,400</td>\n",
       "      <td>21,260</td>\n",
       "      <td>23,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>NHA</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>2021-10</td>\n",
       "      <td>363.2%</td>\n",
       "      <td>7,398</td>\n",
       "      <td>34,270</td>\n",
       "      <td>22,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020</td>\n",
       "      <td>VCF</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>2021-10</td>\n",
       "      <td>20.9%</td>\n",
       "      <td>192,935</td>\n",
       "      <td>233,170</td>\n",
       "      <td>232,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020</td>\n",
       "      <td>VCF</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>40.5%</td>\n",
       "      <td>156,148</td>\n",
       "      <td>219,452</td>\n",
       "      <td>232,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>TMP</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>2020-04</td>\n",
       "      <td>-8.9%</td>\n",
       "      <td>23,020</td>\n",
       "      <td>20,970</td>\n",
       "      <td>71,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019</td>\n",
       "      <td>TMP</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>11.0%</td>\n",
       "      <td>20,370</td>\n",
       "      <td>22,610</td>\n",
       "      <td>71,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>7.0%</td>\n",
       "      <td>37,550</td>\n",
       "      <td>40,170</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>TMP</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>13.7%</td>\n",
       "      <td>18,850</td>\n",
       "      <td>21,440</td>\n",
       "      <td>71,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>DSN</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>2019-10</td>\n",
       "      <td>10.3%</td>\n",
       "      <td>38,720</td>\n",
       "      <td>42,710</td>\n",
       "      <td>56,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>DRL</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>2019-01</td>\n",
       "      <td>11.6%</td>\n",
       "      <td>28,450</td>\n",
       "      <td>31,760</td>\n",
       "      <td>66,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>GDT</td>\n",
       "      <td>2017-10</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>-8.3%</td>\n",
       "      <td>23,860</td>\n",
       "      <td>21,890</td>\n",
       "      <td>27,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>DRL</td>\n",
       "      <td>2017-10</td>\n",
       "      <td>2018-10</td>\n",
       "      <td>40.6%</td>\n",
       "      <td>23,460</td>\n",
       "      <td>32,980</td>\n",
       "      <td>66,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>DRL</td>\n",
       "      <td>2017-07</td>\n",
       "      <td>2018-07</td>\n",
       "      <td>40.1%</td>\n",
       "      <td>22,150</td>\n",
       "      <td>31,040</td>\n",
       "      <td>66,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>GDT</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>-9.5%</td>\n",
       "      <td>22,600</td>\n",
       "      <td>20,450</td>\n",
       "      <td>27,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>2017-07</td>\n",
       "      <td>-3.6%</td>\n",
       "      <td>32,240</td>\n",
       "      <td>31,090</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2016-04</td>\n",
       "      <td>2017-04</td>\n",
       "      <td>55.7%</td>\n",
       "      <td>20,280</td>\n",
       "      <td>31,570</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016</td>\n",
       "      <td>DVP</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>29.1%</td>\n",
       "      <td>32,439</td>\n",
       "      <td>41,870</td>\n",
       "      <td>76,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>LIX</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>2017-01</td>\n",
       "      <td>46.6%</td>\n",
       "      <td>24,660</td>\n",
       "      <td>36,150</td>\n",
       "      <td>67,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>106.2%</td>\n",
       "      <td>17,300</td>\n",
       "      <td>35,670</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015</td>\n",
       "      <td>DSN</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>37.1%</td>\n",
       "      <td>25,960</td>\n",
       "      <td>35,580</td>\n",
       "      <td>56,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>2016-07</td>\n",
       "      <td>119.5%</td>\n",
       "      <td>14,690</td>\n",
       "      <td>32,240</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2015-04</td>\n",
       "      <td>2016-04</td>\n",
       "      <td>39.4%</td>\n",
       "      <td>14,550</td>\n",
       "      <td>20,280</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015</td>\n",
       "      <td>DSN</td>\n",
       "      <td>2015-01</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>40.1%</td>\n",
       "      <td>21,120</td>\n",
       "      <td>29,580</td>\n",
       "      <td>56,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2015-01</td>\n",
       "      <td>2016-01</td>\n",
       "      <td>22.6%</td>\n",
       "      <td>13,990</td>\n",
       "      <td>17,150</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014</td>\n",
       "      <td>DSN</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>27.0%</td>\n",
       "      <td>20,440</td>\n",
       "      <td>25,960</td>\n",
       "      <td>56,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014</td>\n",
       "      <td>DRL</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>13,360</td>\n",
       "      <td>16,520</td>\n",
       "      <td>66,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>2015-10</td>\n",
       "      <td>41.7%</td>\n",
       "      <td>12,210</td>\n",
       "      <td>17,300</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2014</td>\n",
       "      <td>DRL</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>42.1%</td>\n",
       "      <td>11,930</td>\n",
       "      <td>16,950</td>\n",
       "      <td>66,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2014</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2014-07</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>33.8%</td>\n",
       "      <td>10,980</td>\n",
       "      <td>14,690</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2014</td>\n",
       "      <td>C32</td>\n",
       "      <td>2014-04</td>\n",
       "      <td>2015-04</td>\n",
       "      <td>19.5%</td>\n",
       "      <td>11,870</td>\n",
       "      <td>14,180</td>\n",
       "      <td>18,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2014</td>\n",
       "      <td>DRL</td>\n",
       "      <td>2014-04</td>\n",
       "      <td>2015-04</td>\n",
       "      <td>33.5%</td>\n",
       "      <td>12,140</td>\n",
       "      <td>16,210</td>\n",
       "      <td>66,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2014-01</td>\n",
       "      <td>2015-01</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>7,810</td>\n",
       "      <td>13,990</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013</td>\n",
       "      <td>DPM</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2014-01</td>\n",
       "      <td>9.9%</td>\n",
       "      <td>14,990</td>\n",
       "      <td>16,480</td>\n",
       "      <td>35,850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013</td>\n",
       "      <td>NNC</td>\n",
       "      <td>2013-01</td>\n",
       "      <td>2014-01</td>\n",
       "      <td>33.7%</td>\n",
       "      <td>5,840</td>\n",
       "      <td>7,810</td>\n",
       "      <td>17,700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    buying_year ticker buying_time selling_time  return buying_price  \\\n",
       "0          2023    VIP     2023-07      2024-07   -7.8%       12,200   \n",
       "1          2023    DSN     2023-04      2024-04    4.6%       53,920   \n",
       "2          2022    ST8     2022-07      2023-07   52.2%       15,700   \n",
       "3          2021    ADP     2021-04      2022-04   22.2%       17,400   \n",
       "4          2020    NHA     2020-10      2021-10  363.2%        7,398   \n",
       "5          2020    VCF     2020-10      2021-10   20.9%      192,935   \n",
       "6          2020    VCF     2020-01      2021-01   40.5%      156,148   \n",
       "7          2019    TMP     2019-04      2020-04   -8.9%       23,020   \n",
       "8          2019    TMP     2019-01      2020-01   11.0%       20,370   \n",
       "9          2019    NNC     2019-01      2020-01    7.0%       37,550   \n",
       "10         2018    TMP     2018-10      2019-10   13.7%       18,850   \n",
       "11         2018    DSN     2018-10      2019-10   10.3%       38,720   \n",
       "12         2018    DRL     2018-01      2019-01   11.6%       28,450   \n",
       "13         2017    GDT     2017-10      2018-10   -8.3%       23,860   \n",
       "14         2017    DRL     2017-10      2018-10   40.6%       23,460   \n",
       "15         2017    DRL     2017-07      2018-07   40.1%       22,150   \n",
       "16         2017    GDT     2017-04      2018-04   -9.5%       22,600   \n",
       "17         2016    NNC     2016-07      2017-07   -3.6%       32,240   \n",
       "18         2016    NNC     2016-04      2017-04   55.7%       20,280   \n",
       "19         2016    DVP     2016-01      2017-01   29.1%       32,439   \n",
       "20         2016    LIX     2016-01      2017-01   46.6%       24,660   \n",
       "21         2015    NNC     2015-10      2016-10  106.2%       17,300   \n",
       "22         2015    DSN     2015-10      2016-10   37.1%       25,960   \n",
       "23         2015    NNC     2015-07      2016-07  119.5%       14,690   \n",
       "24         2015    NNC     2015-04      2016-04   39.4%       14,550   \n",
       "25         2015    DSN     2015-01      2016-01   40.1%       21,120   \n",
       "26         2015    NNC     2015-01      2016-01   22.6%       13,990   \n",
       "27         2014    DSN     2014-10      2015-10   27.0%       20,440   \n",
       "28         2014    DRL     2014-10      2015-10   23.7%       13,360   \n",
       "29         2014    NNC     2014-10      2015-10   41.7%       12,210   \n",
       "30         2014    DRL     2014-07      2015-07   42.1%       11,930   \n",
       "31         2014    NNC     2014-07      2015-07   33.8%       10,980   \n",
       "32         2014    C32     2014-04      2015-04   19.5%       11,870   \n",
       "33         2014    DRL     2014-04      2015-04   33.5%       12,140   \n",
       "34         2014    NNC     2014-01      2015-01   79.1%        7,810   \n",
       "35         2013    DPM     2013-01      2014-01    9.9%       14,990   \n",
       "36         2013    NNC     2013-01      2014-01   33.7%        5,840   \n",
       "\n",
       "   selling_price latest_price  \n",
       "0            nan       11,250  \n",
       "1            nan       56,400  \n",
       "2         23,900       10,550  \n",
       "3         21,260       23,600  \n",
       "4         34,270       22,300  \n",
       "5        233,170      232,700  \n",
       "6        219,452      232,700  \n",
       "7         20,970       71,400  \n",
       "8         22,610       71,400  \n",
       "9         40,170       17,700  \n",
       "10        21,440       71,400  \n",
       "11        42,710       56,400  \n",
       "12        31,760       66,600  \n",
       "13        21,890       27,500  \n",
       "14        32,980       66,600  \n",
       "15        31,040       66,600  \n",
       "16        20,450       27,500  \n",
       "17        31,090       17,700  \n",
       "18        31,570       17,700  \n",
       "19        41,870       76,300  \n",
       "20        36,150       67,500  \n",
       "21        35,670       17,700  \n",
       "22        35,580       56,400  \n",
       "23        32,240       17,700  \n",
       "24        20,280       17,700  \n",
       "25        29,580       56,400  \n",
       "26        17,150       17,700  \n",
       "27        25,960       56,400  \n",
       "28        16,520       66,600  \n",
       "29        17,300       17,700  \n",
       "30        16,950       66,600  \n",
       "31        14,690       17,700  \n",
       "32        14,180       18,000  \n",
       "33        16,210       66,600  \n",
       "34        13,990       17,700  \n",
       "35        16,480       35,850  \n",
       "36         7,810       17,700  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con1 = merged_df['G7'] == 7\n",
    "\n",
    "summary = merged_df[con1]\n",
    "summary = summary[['buying_year', 'ticker', 'buying_time', 'selling_time', 'return', 'buying_price', 'selling_price','latest_price']]\n",
    "summary = summary.sort_values(by='buying_time', ascending=False)  # Sorting by 'buying_time' in descending order\n",
    "summary.reset_index(drop=True, inplace=True)  # Resetting index while dropping the old index\n",
    "summary['return'] = (summary['return'] * 100).round(1).astype(str) + '%'\n",
    "summary['buying_price'] = summary['buying_price'].apply(lambda x: '{:,.{}f}'.format(x, 0 if x == int(x) else 2))\n",
    "summary['selling_price'] = summary['selling_price'].apply(lambda x: '{:,.{}f}'.format(x, 0 if np.isnan(x) or x == int(x) else 2))\n",
    "summary['latest_price'] = summary['latest_price'].apply(lambda x: '{:,.{}f}'.format(x, 0 if x == int(x) else 2))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0dfebf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'C:/Users/atlas/OneDrive/Desktop/vnstock/summary.csv'\n",
    "summary.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Open the CSV file\n",
    "os.startfile(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2822c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'C:/Users/atlas/OneDrive/Desktop/vnstock/merged_df.csv'\n",
    "merged_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Open the CSV file\n",
    "os.startfile(csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
